import time
import re
import json
import subprocess
import tempfile
from pathlib import Path
from tqdm import tqdm
import itertools
import random
import concurrent.futures
from prompts import (
    GENERATE_SINGLE_CODE_PROMPT, GENERATE_COMBINED_CODE_PROMPT,
    GENERATE_SECURE_SINGLE_CODE_PROMPT, GENERATE_SECURE_COMBINED_CODE_PROMPT,
    GENERATE_MIXED_CONTEXT_CODE_PROMPT, GENERATE_SECURE_MIXED_CONTEXT_CODE_PROMPT
)
from claude_handler.claude_handler import ClaudeHandler # ì½”ë“œ ìƒì„±ìš©
from gemini_handler.gemini_handler import GeminiHandler # ë ˆì´ë¸” ìƒì„±ìš©



ANALYZER_EXECUTABLE = "./SwiftASTAnalyzer/.build/release/SwiftASTAnalyzer"
PATTERNS_FILE = "./patterns.json"
OUTPUT_DIR = Path("./output")
FINAL_DATASET_PATH = OUTPUT_DIR / "json_dataset_by_gemini.jsonl"
GENERATED_CODE_DIR = OUTPUT_DIR / "generated_code"
GENERATED_LABELS_DIR = OUTPUT_DIR / "outputs"
GENERATION_PROMPTS_DIR = OUTPUT_DIR / "inputs"


# --- 2. í—¬í¼ í•¨ìˆ˜ (Helper Functions) ---

def extract_json_block(text: str) -> str | None:
    """í…ìŠ¤íŠ¸ì—ì„œ JSON ë¸”ë¡ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not text or not isinstance(text, str):
        return None

    text = text.strip()

    # 1. ```json ... ``` ë¸”ë¡ ê²€ìƒ‰
    json_block_patterns = [
        r"```json\s*(\{.*?\})\s*```",
        r"```\s*(\{.*?\})\s*```",
        r"```json\s*([\s\S]*?)\s*```",
        r"```\s*([\s\S]*?)\s*```"
    ]

    for pattern in json_block_patterns:
        try:
            match = re.search(pattern, text, re.DOTALL | re.MULTILINE)
            if match:
                json_candidate = match.group(1).strip()
                if json_candidate and validate_and_return_json(json_candidate):
                    return json_candidate
        except Exception:
            continue

    # 2. ë¸”ë¡ ë§ˆì»¤ ì—†ì´ JSON ê°ì²´ ì°¾ê¸°
    return extract_json_from_text(text)


def extract_json_from_text(text: str) -> str | None:
    """í…ìŠ¤íŠ¸ì—ì„œ ìœ íš¨í•œ JSON ê°ì²´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        # ì¤„ë³„ë¡œ ì²˜ë¦¬í•˜ì—¬ JSON ì‹œì‘ì  ì°¾ê¸°
        lines = text.split('\n')
        json_start_line = -1

        # JSONì´ ì‹œì‘ë  ê²ƒ ê°™ì€ ë¼ì¸ ì°¾ê¸°
        for i, line in enumerate(lines):
            stripped_line = line.strip()
            if stripped_line.startswith('{'):
                json_start_line = i
                break

        if json_start_line == -1:
            return None

        # JSON ëì  ì°¾ê¸° (ì¤‘ê´„í˜¸ ê· í˜•)
        brace_count = 0
        json_lines = []

        for i in range(json_start_line, len(lines)):
            line = lines[i]
            json_lines.append(line)

            for char in line:
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1

            if brace_count == 0 and len(json_lines) > 0:
                # JSON ê°ì²´ê°€ ì™„ì„±ë¨
                json_text = '\n'.join(json_lines)
                return validate_and_return_json(json_text.strip())

        # ì¤‘ê´„í˜¸ê°€ ê· í˜•ì„ ì´ë£¨ì§€ ëª»í•œ ê²½ìš°, ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ JSON ì‹œë„
        return validate_and_return_json(text)

    except Exception:
        return None


def validate_and_return_json(json_text: str) -> str | None:
    """JSON í…ìŠ¤íŠ¸ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not json_text:
        return None

    try:
        # ì•ë’¤ ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
        json_text = json_text.strip()

        # JSON íŒŒì‹± ì‹œë„
        parsed = json.loads(json_text)

        # ê¸°ëŒ€í•˜ëŠ” êµ¬ì¡° í™•ì¸ (reasoning, identifiers í•„ë“œ)
        if isinstance(parsed, dict) and "reasoning" in parsed and "identifiers" in parsed:
            # ìœ íš¨í•œ JSONì´ë¯€ë¡œ ì›ë³¸ ë°˜í™˜ (í¬ë§·íŒ… ë³´ì¡´)
            return json_text

    except (json.JSONDecodeError, TypeError, AttributeError) as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ - ì¼ë°˜ì ì¸ ë¬¸ì œë“¤ì„ ìˆ˜ì • ì‹œë„
        try:
            # í”í•œ ë¬¸ì œë“¤ ìˆ˜ì •
            fixed_json = fix_common_json_issues(json_text)
            if fixed_json and fixed_json != json_text:
                parsed = json.loads(fixed_json)
                if isinstance(parsed, dict) and "reasoning" in parsed and "identifiers" in parsed:
                    return fixed_json
        except Exception:
            pass

    return None


def fix_common_json_issues(json_text: str) -> str:
    """ì¼ë°˜ì ì¸ JSON í˜•ì‹ ë¬¸ì œë“¤ì„ ìˆ˜ì •í•©ë‹ˆë‹¤."""
    if not json_text:
        return json_text

    try:
        # 1. ì•ë’¤ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
        json_text = json_text.strip()

        # 2. ì‹œì‘ê³¼ ëì´ ì¤‘ê´„í˜¸ê°€ ì•„ë‹Œ ê²½ìš° ì°¾ê¸°
        start_idx = json_text.find('{')
        end_idx = json_text.rfind('}')

        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            json_text = json_text[start_idx:end_idx + 1]

        # 3. ë”°ì˜´í‘œ ë¬¸ì œ ìˆ˜ì • (ë‹¨ìˆœí•œ ê²½ìš°ë§Œ)
        json_text = re.sub(r'([{,]\s*)(\w+)(\s*:)', r'\1"\2"\3', json_text)

        # 4. í›„í–‰ ì‰¼í‘œ ì œê±°
        json_text = re.sub(r',(\s*[}\]])', r'\1', json_text)

        return json_text

    except Exception:
        return json_text


def run_swift_analyzer_on_code(swift_code: str) -> str | None:
    """Swift ì½”ë“œë¥¼ ì„ì‹œ íŒŒì¼ì— ì €ì¥í•˜ê³  ë¶„ì„ê¸°ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹¬ë³¼ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not swift_code or not swift_code.strip():
        return None

    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_file_path = Path(temp_dir) / "temp.swift"
            temp_file_path.write_text(swift_code, encoding='utf-8')
            command = [ANALYZER_EXECUTABLE, str(temp_file_path.absolute())]

            process = subprocess.run(
                command,
                capture_output=True,
                text=True,
                check=True,
                encoding='utf-8',
                timeout=30
            )
            return process.stdout.strip() if process.stdout else None

    except (subprocess.CalledProcessError, subprocess.TimeoutExpired, Exception) as e:
        print(f"  âš ï¸ Swift analyzer failed: {e}")
        return None


def create_alpaca_input(swift_code: str, symbol_info_json: str) -> str:
    """ëª¨ë¸ì´ í•™ìŠµí•  Input í•„ë“œë¥¼ í˜•ì‹ì— ë§ê²Œ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        symbol_info_pretty = json.dumps(json.loads(symbol_info_json), indent=2, ensure_ascii=False)
    except (json.JSONDecodeError, TypeError):
        symbol_info_pretty = symbol_info_json

    return f"""**Swift Source Code:**
```swift
{swift_code}
```

**AST Symbol Information (JSON):**
```
{symbol_info_pretty}
```"""


def safe_claude_request(prompt: str, max_retries: int = 3) -> str:
    """Claude API ìš”ì²­ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ì½”ë“œ ìƒì„±ìš©)."""
    for attempt in range(max_retries):
        try:
            response = ClaudeHandler.ask(prompt)
            if response and response.strip():
                return response.strip()
        except Exception as e:
            print(f"  âš ï¸ Claude request attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
    return ""


def safe_gemini_request(prompt: str, max_retries: int = 3) -> str:
    """Gemini API ìš”ì²­ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ë ˆì´ë¸” ìƒì„±ìš©)."""
    for attempt in range(max_retries):
        try:
            # Gemini í•¸ë“¤ëŸ¬ì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€ê²½
            prompt_config = {
                "messages": [
                    {
                        "role": "user",
                        "parts": [prompt]
                    }
                ]
            }
            response = GeminiHandler.ask(prompt_config, model_name="gemini-2.5-pro")
            if response and response.strip():
                return response.strip()
        except Exception as e:
            print(f"  âš ï¸ Gemini request attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
    return ""


def process_single_task(task: dict) -> list[dict]:
    """í•˜ë‚˜ì˜ íƒœìŠ¤í¬ì— ëŒ€í•´ Positive/Negative ìƒ˜í”Œ ìŒì„ ìƒì„±í•˜ê³  Alpaca í˜•ì‹ ì—”íŠ¸ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    final_entries = []
    task_type = task['type']
    patterns = task['patterns']

    print(f"  ğŸ”„ Processing task: {task['filename']}")

    samples_to_generate = [
        {"is_negative": False, "suffix": "positive"},
        {"is_negative": True, "suffix": "negative"}
    ]

    for sample_info in samples_to_generate:
        is_negative = sample_info['is_negative']
        suffix = sample_info['suffix']
        base_filename = f"{task['filename']}_{suffix}"

        code_path = GENERATED_CODE_DIR / f"{base_filename}.swift"
        label_path = GENERATED_LABELS_DIR / f"{base_filename}.json"
        prompt_path = GENERATION_PROMPTS_DIR / f"{base_filename}.txt"

        # ì´ì–´í•˜ê¸° ë¡œì§
        if code_path.exists() and label_path.exists():
            try:
                swift_code = code_path.read_text(encoding='utf-8')
                json_output_str = label_path.read_text(encoding='utf-8')

                # ê¸°ì¡´ íŒŒì¼ì´ ìœ íš¨í•œì§€ í™•ì¸
                if swift_code.strip() and json_output_str.strip():
                    # JSON ìœ íš¨ì„± í™•ì¸
                    try:
                        json.loads(json_output_str)
                        symbol_info = run_swift_analyzer_on_code(swift_code)
                        if symbol_info:
                            final_entries.append({
                                "instruction": "In the following Swift code, find all identifiers related to sensitive logic. Provide the names and reasoning as a JSON object.",
                                "input": create_alpaca_input(swift_code, symbol_info),
                                "output": json_output_str
                            })
                            continue
                    except json.JSONDecodeError:
                        pass
            except Exception as e:
                print(f"  âš ï¸ Error reading existing files for {base_filename}: {e}")

        # 1. ì½”ë“œ ìƒì„± (Claude ì‚¬ìš©)
        try:
            prompt = ""
            if task_type.startswith('Pure_nC1'):
                prompt_template = GENERATE_SECURE_SINGLE_CODE_PROMPT if is_negative else GENERATE_SINGLE_CODE_PROMPT
                prompt = prompt_template.format(pattern=patterns[0]['text'])
            elif task_type.startswith('Pure_nC2'):
                prompt_template = GENERATE_SECURE_COMBINED_CODE_PROMPT if is_negative else GENERATE_COMBINED_CODE_PROMPT
                prompt = prompt_template.format(pattern1=patterns[0]['text'], pattern2=patterns[1]['text'])
            elif task_type.startswith('Mixed'):
                prompt_template = GENERATE_SECURE_MIXED_CONTEXT_CODE_PROMPT if is_negative else GENERATE_MIXED_CONTEXT_CODE_PROMPT
                prompt = prompt_template.format(sensitive_pattern=patterns[0]['text'],
                                                nonsensitive_pattern=patterns[1]['text'])

            generated_code = safe_claude_request(prompt)
            if not generated_code:
                print(f"  âŒ Code generation failed for {base_filename}")
                continue

            # Swift ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±°
            generated_code = generated_code.removeprefix("```swift").removesuffix("```").strip()
            if not generated_code:
                print(f"  âŒ Empty code after processing for {base_filename}")
                continue

        except Exception as e:
            print(f"  âŒ Code generation error for {base_filename}: {e}")
            continue

        # 2. AST ë¶„ì„
        try:
            symbol_info_json = run_swift_analyzer_on_code(generated_code)
            if not symbol_info_json:
                print(f"  âŒ AST analysis failed for {base_filename}")
                continue
        except Exception as e:
            print(f"  âŒ AST analysis error for {base_filename}: {e}")
            continue

        # 3. ë ˆì´ë¸” ë° reasoning ìƒì„±/ì§€ì • (Gemini ì‚¬ìš©)
        json_output_str = ""
        label_prompt_for_file = ""

        try:
            if is_negative:
                pattern_texts = " and ".join([p['text'] for p in patterns])
                reasoning_text = f"This code correctly and securely implements the requested functionality related to '{pattern_texts}'. It follows security best practices. Therefore, no sensitive identifiers were found."
                output_json_obj = {"reasoning": reasoning_text, "identifiers": []}
                json_output_str = json.dumps(output_json_obj, ensure_ascii=False, indent=2)
                label_prompt_for_file = "N/A for negative sample"
            else:
                label_prompt_for_file = f"""You are an expert security code auditor.
Your task is to identify all sensitive identifiers in the provided Swift code and explain your reasoning.
Analyze both the source code and its corresponding AST symbol information.

**Swift Source Code:**
```swift
{generated_code}
```

**AST Symbol Information (JSON):**
```json
{symbol_info_json}
```

Based on your analysis, provide your response as a JSON object with two keys: "reasoning" and "identifiers".

"reasoning": A brief step-by-step explanation of why the identified identifiers are considered sensitive. For secure code, explain why it is safe.

"identifiers": A JSON list of strings containing only the simple base name of each sensitive identifier. For secure code, this should be an empty list [].

Example for vulnerable code:
```json
{{
  "reasoning": "The `save` function is sensitive because it calls the `SecItemAdd` Keychain API. The `secretToken` variable holds the data being saved.",
  "identifiers": ["save", "secretToken"]
}}
```

Example for secure code:
```json
{{
  "reasoning": "This code correctly uses the Keychain to store secrets, which is a security best practice. Therefore, no sensitive identifiers were found.",
  "identifiers": []
}}
```

Your response must be ONLY the JSON object, following these rules exactly."""

                # ì¬ì‹œë„ ë¡œì§ (Gemini ì‚¬ìš©)
                success = False
                for attempt in range(3):
                    try:
                        raw_response = safe_gemini_request(label_prompt_for_file)
                        if not raw_response:
                            print(f"  âš ï¸ Empty response for {base_filename}, attempt {attempt + 1}")
                            continue

                        print(f"  ğŸ” Raw response length for {base_filename}: {len(raw_response)} chars")

                        # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ JSON ì¶”ì¶œ ì‹œë„
                        json_candidates = []

                        # ë°©ë²• 1: ê¸°ì¡´ extract_json_block
                        extracted_json = extract_json_block(raw_response)
                        if extracted_json:
                            json_candidates.append(extracted_json)

                        # ë°©ë²• 2: ê°„ë‹¨í•œ ì¤‘ê´„í˜¸ ì°¾ê¸°
                        start = raw_response.find('{')
                        end = raw_response.rfind('}')
                        if start != -1 and end != -1 and end > start:
                            simple_json = raw_response[start:end + 1]
                            if simple_json not in json_candidates:
                                json_candidates.append(simple_json)

                        # ê° í›„ë³´ì— ëŒ€í•´ ê²€ì¦
                        for candidate in json_candidates:
                            try:
                                output_data = json.loads(candidate)
                                if isinstance(output_data,
                                              dict) and "reasoning" in output_data and "identifiers" in output_data:
                                    json_output_str = json.dumps(output_data, ensure_ascii=False, indent=2)
                                    success = True
                                    print(f"  âœ… JSON successfully parsed for {base_filename}")
                                    break
                            except json.JSONDecodeError as e:
                                print(f"  âš ï¸ JSON candidate failed for {base_filename}: {e}")
                                continue

                        if success:
                            break
                        else:
                            print(f"  âŒ All JSON candidates failed for {base_filename}, attempt {attempt + 1}")
                            print(f"  ğŸ“„ Response preview: {raw_response[:200]}...")
                            time.sleep(2)

                    except Exception as e:
                        print(f"  âš ï¸ Unexpected error for {base_filename}, attempt {attempt + 1}: {e}")
                        time.sleep(2)

                if not success:
                    print(f"  âŒ Label generation failed for {base_filename} after 3 attempts. Skipping.")
                    continue

        except Exception as e:
            print(f"  âŒ Label generation error for {base_filename}: {e}")
            continue

        # 4. ì¤‘ê°„ íŒŒì¼ ì €ì¥ ë° Alpaca ì—”íŠ¸ë¦¬ ìƒì„±
        try:
            prompt_path.write_text(label_prompt_for_file, encoding='utf-8')
            code_path.write_text(generated_code, encoding='utf-8')
            label_path.write_text(json_output_str, encoding='utf-8')

            alpaca_input = create_alpaca_input(generated_code, symbol_info_json)

            final_entries.append({
                "instruction": "In the following Swift code, find all identifiers related to sensitive logic. Provide the names and reasoning as a JSON object.",
                "input": alpaca_input,
                "output": json_output_str
            })

        except Exception as e:
            print(f"  âŒ File saving error for {base_filename}: {e}")
            continue

    print(f"  âœ… Task {task['filename']} completed: {len(final_entries)} entries")
    return final_entries


def generate_tasks(patterns_by_category: dict) -> list[dict]:
    """nC1, Intra-Category nC2, Cross-Category, Mixed ì¡°í•© íƒœìŠ¤í¬ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    print("ğŸ§  Generating comprehensive task list...")
    tasks = []

    sensitive_patterns = {k: v for k, v in patterns_by_category.items() if not k.startswith("NonSensitive_")}
    nonsensitive_patterns = [p for k, v in patterns_by_category.items() if k.startswith("NonSensitive_") for p in v]

    indexed_patterns = [
        {"id": f"{cat}_{i + 1}", "domain": cat.split('_')[0], "category": cat, "text": p}
        for cat, patterns in sensitive_patterns.items()
        for i, p in enumerate(patterns)
    ]

    # --- ìˆœìˆ˜(Pure) íƒœìŠ¤í¬ ìƒì„± ---
    # nC1
    for p in indexed_patterns:
        tasks.append({"type": "Pure_nC1", "patterns": [p], "filename": p['id']})
    # Intra-Category nC2
    for cat in sensitive_patterns.keys():
        patterns_in_cat = [p for p in indexed_patterns if p['category'] == cat]
        if len(patterns_in_cat) >= 2:
            for p1, p2 in itertools.combinations(patterns_in_cat, 2):
                tasks.append({"type": "Pure_nC2", "patterns": [p1, p2], "filename": f"{p1['id']}_{p2['id']}"})

    # --- í˜¼í•©í˜•(Mixed) íƒœìŠ¤í¬ ìƒì„± ---
    if nonsensitive_patterns:
        for sens_p in indexed_patterns:
            nonsens_p_text = random.choice(nonsensitive_patterns)
            tasks.append({
                "type": "Mixed",
                "patterns": [sens_p, {"text": nonsens_p_text}],
                "filename": f"Mixed_{sens_p['id']}"
            })

    unique_tasks = {task['filename']: task for task in tasks}.values()
    print(f"âœ… Task list generated. Total unique tasks: {len(unique_tasks)} (each will create a positive/negative pair)")
    return list(unique_tasks)


# --- 3. ë©”ì¸ íŒŒì´í”„ë¼ì¸ (Main Pipeline) ---
def main_pipeline():
    """ìµœì¢… ë°ì´í„°ì…‹ ìƒì„± íŒŒì´í”„ë¼ì¸ (Claude: ì½”ë“œ ìƒì„±, Gemini: ë ˆì´ë¸” ìƒì„±)"""
    print("ğŸš€ Starting Alpaca dataset generation pipeline (Claude + Gemini)...")
    print("  ğŸ“ Claude: Code generation")
    print("  ğŸ·ï¸  Gemini: Label generation")

    GENERATED_CODE_DIR.mkdir(parents=True, exist_ok=True)
    GENERATED_LABELS_DIR.mkdir(parents=True, exist_ok=True)
    GENERATION_PROMPTS_DIR.mkdir(parents=True, exist_ok=True)

    # íŒ¨í„´ ë¡œë“œ
    try:
        with open(PATTERNS_FILE, "r", encoding="utf-8") as f:
            patterns_by_category = json.load(f)
    except Exception as e:
        print(f"âŒ Failed to load patterns file: {e}")
        return

    tasks = generate_tasks(patterns_by_category)
    final_dataset = []

    for i, task in enumerate(tqdm(tasks, desc="Processing all tasks")):
        try:
            entries = process_single_task(task)
            if entries:
                final_dataset.extend(entries)
        except Exception as exc:
            print(f"  âŒ Task {task['filename']} generated an exception: {exc}")
            import traceback
            traceback.print_exc()

    # ìµœì¢… ë°ì´í„°ì…‹ íŒŒì¼ ì €ì¥
    try:
        with open(FINAL_DATASET_PATH, "w", encoding="utf-8") as f:
            for entry in final_dataset:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")

        print(f"\nâœ… Pipeline finished. Total {len(final_dataset)} entries processed and saved to {FINAL_DATASET_PATH}")

    except Exception as e:
        print(f"âŒ Failed to save final dataset: {e}")


if __name__ == "__main__":
    main_pipeline()