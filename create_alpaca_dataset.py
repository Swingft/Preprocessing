import time
import re
import json
import subprocess
import tempfile
from pathlib import Path
from tqdm import tqdm
import itertools
import random
import concurrent.futures
from prompts import (
    GENERATE_SINGLE_CODE_PROMPT, GENERATE_COMBINED_CODE_PROMPT,
    GENERATE_SECURE_SINGLE_CODE_PROMPT, GENERATE_SECURE_COMBINED_CODE_PROMPT,
    GENERATE_MIXED_CONTEXT_CODE_PROMPT, GENERATE_SECURE_MIXED_CONTEXT_CODE_PROMPT
)
from claude_handler.claude_handler import ClaudeHandler  # ì½”ë“œ ìƒì„±ìš©
from gemini_handler.gemini_handler import GeminiHandler  # ì½”ë“œ ìƒì„± + ë ˆì´ë¸” ìƒì„±ìš©

ANALYZER_EXECUTABLE = "./SwiftASTAnalyzer/.build/release/SwiftASTAnalyzer"
PATTERNS_FILE = "./patterns.json"
OUTPUT_DIR = Path("./output")

# ê° ìƒì„±ê¸°ë³„ ë””ë ‰í† ë¦¬ êµ¬ì¡°
GENERATED_CODE_CLAUDE = OUTPUT_DIR / "generated_code" / "claude_generated"
GENERATED_CODE_GEMINI = OUTPUT_DIR / "generated_code" / "gemini_generated"
GENERATED_LABELS_CLAUDE = OUTPUT_DIR / "outputs" / "claude_generated"
GENERATED_LABELS_GEMINI = OUTPUT_DIR / "outputs" / "gemini_generated"
GENERATION_PROMPTS_CLAUDE = OUTPUT_DIR / "inputs" / "claude_generated"
GENERATION_PROMPTS_GEMINI = OUTPUT_DIR / "inputs" / "gemini_generated"

# ìµœì¢… ë°ì´í„°ì…‹ íŒŒì¼ë“¤
FINAL_DATASET_CLAUDE_ONLY = OUTPUT_DIR / "claude_only_dataset.jsonl"
FINAL_DATASET_GEMINI_ONLY = OUTPUT_DIR / "gemini_only_dataset.jsonl"
FINAL_DATASET_COMBINED = OUTPUT_DIR / "combined_dataset.jsonl"


# --- 2. í—¬í¼ í•¨ìˆ˜ (Helper Functions) ---

def extract_json_block(text: str) -> str | None:
    """í…ìŠ¤íŠ¸ì—ì„œ JSON ë¸”ë¡ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not text or not isinstance(text, str):
        return None

    text = text.strip()

    # 1. ```json ... ``` ë¸”ë¡ ê²€ìƒ‰
    json_block_patterns = [
        r"```json\s*(\{.*?\})\s*```",
        r"```\s*(\{.*?\})\s*```",
        r"```json\s*([\s\S]*?)\s*```",
        r"```\s*([\s\S]*?)\s*```"
    ]

    for pattern in json_block_patterns:
        try:
            match = re.search(pattern, text, re.DOTALL | re.MULTILINE)
            if match:
                json_candidate = match.group(1).strip()
                if json_candidate and validate_and_return_json(json_candidate):
                    return json_candidate
        except Exception:
            continue

    # 2. ë¸”ë¡ ë§ˆì»¤ ì—†ì´ JSON ê°ì²´ ì°¾ê¸°
    return extract_json_from_text(text)


def extract_json_from_text(text: str) -> str | None:
    """í…ìŠ¤íŠ¸ì—ì„œ ìœ íš¨í•œ JSON ê°ì²´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        # ì¤„ë³„ë¡œ ì²˜ë¦¬í•˜ì—¬ JSON ì‹œì‘ì  ì°¾ê¸°
        lines = text.split('\n')
        json_start_line = -1

        # JSONì´ ì‹œì‘ë  ê²ƒ ê°™ì€ ë¼ì¸ ì°¾ê¸°
        for i, line in enumerate(lines):
            stripped_line = line.strip()
            if stripped_line.startswith('{'):
                json_start_line = i
                break

        if json_start_line == -1:
            return None

        # JSON ëì  ì°¾ê¸° (ì¤‘ê´„í˜¸ ê· í˜•)
        brace_count = 0
        json_lines = []

        for i in range(json_start_line, len(lines)):
            line = lines[i]
            json_lines.append(line)

            for char in line:
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1

            if brace_count == 0 and len(json_lines) > 0:
                # JSON ê°ì²´ê°€ ì™„ì„±ë¨
                json_text = '\n'.join(json_lines)
                return validate_and_return_json(json_text.strip())

        # ì¤‘ê´„í˜¸ê°€ ê· í˜•ì„ ì´ë£¨ì§€ ëª»í•œ ê²½ìš°, ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ JSON ì‹œë„
        return validate_and_return_json(text)

    except Exception:
        return None


def validate_and_return_json(json_text: str) -> str | None:
    """JSON í…ìŠ¤íŠ¸ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not json_text:
        return None

    try:
        # ì•ë’¤ ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
        json_text = json_text.strip()

        # JSON íŒŒì‹± ì‹œë„
        parsed = json.loads(json_text)

        # ê¸°ëŒ€í•˜ëŠ” êµ¬ì¡° í™•ì¸ (reasoning, identifiers í•„ë“œ)
        if isinstance(parsed, dict) and "reasoning" in parsed and "identifiers" in parsed:
            # ìœ íš¨í•œ JSONì´ë¯€ë¡œ ì›ë³¸ ë°˜í™˜ (í¬ë§·íŒ… ë³´ì¡´)
            return json_text

    except (json.JSONDecodeError, TypeError, AttributeError) as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ - ì¼ë°˜ì ì¸ ë¬¸ì œë“¤ì„ ìˆ˜ì • ì‹œë„
        try:
            # í”í•œ ë¬¸ì œë“¤ ìˆ˜ì •
            fixed_json = fix_common_json_issues(json_text)
            if fixed_json and fixed_json != json_text:
                parsed = json.loads(fixed_json)
                if isinstance(parsed, dict) and "reasoning" in parsed and "identifiers" in parsed:
                    return fixed_json
        except Exception:
            pass

    return None


def fix_common_json_issues(json_text: str) -> str:
    """ì¼ë°˜ì ì¸ JSON í˜•ì‹ ë¬¸ì œë“¤ì„ ìˆ˜ì •í•©ë‹ˆë‹¤."""
    if not json_text:
        return json_text

    try:
        # 1. ì•ë’¤ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
        json_text = json_text.strip()

        # 2. ì‹œì‘ê³¼ ëì´ ì¤‘ê´„í˜¸ê°€ ì•„ë‹Œ ê²½ìš° ì°¾ê¸°
        start_idx = json_text.find('{')
        end_idx = json_text.rfind('}')

        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            json_text = json_text[start_idx:end_idx + 1]

        # 3. ë”°ì˜´í‘œ ë¬¸ì œ ìˆ˜ì • (ë‹¨ìˆœí•œ ê²½ìš°ë§Œ)
        json_text = re.sub(r'([{,]\s*)(\w+)(\s*:)', r'\1"\2"\3', json_text)

        # 4. í›„í–‰ ì‰¼í‘œ ì œê±°
        json_text = re.sub(r',(\s*[}\]])', r'\1', json_text)

        return json_text

    except Exception:
        return json_text


def run_swift_analyzer_on_code(swift_code: str) -> str | None:
    """Swift ì½”ë“œë¥¼ ì„ì‹œ íŒŒì¼ì— ì €ì¥í•˜ê³  ë¶„ì„ê¸°ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹¬ë³¼ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not swift_code or not swift_code.strip():
        return None

    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_file_path = Path(temp_dir) / "temp.swift"
            temp_file_path.write_text(swift_code, encoding='utf-8')
            command = [ANALYZER_EXECUTABLE, str(temp_file_path.absolute())]

            process = subprocess.run(
                command,
                capture_output=True,
                text=True,
                check=True,
                encoding='utf-8',
                timeout=30
            )
            return process.stdout.strip() if process.stdout else None

    except (subprocess.CalledProcessError, subprocess.TimeoutExpired, Exception) as e:
        print(f"  âš ï¸ Swift analyzer failed: {e}")
        return None


def create_alpaca_input(swift_code: str, symbol_info_json: str) -> str:
    """ëª¨ë¸ì´ í•™ìŠµí•  Input í•„ë“œë¥¼ í˜•ì‹ì— ë§ê²Œ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        symbol_info_pretty = json.dumps(json.loads(symbol_info_json), indent=2, ensure_ascii=False)
    except (json.JSONDecodeError, TypeError):
        symbol_info_pretty = symbol_info_json

    return f"""**Swift Source Code:**
```swift
{swift_code}
```

**AST Symbol Information (JSON):**
```
{symbol_info_pretty}
```"""


def safe_claude_request(prompt: str, max_retries: int = 3) -> str:
    """Claude API ìš”ì²­ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ì½”ë“œ ìƒì„±ìš©)."""
    for attempt in range(max_retries):
        try:
            response = ClaudeHandler.ask(prompt)
            if response and response.strip():
                return response.strip()
        except Exception as e:
            print(f"  âš ï¸ Claude request attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
    return ""


def safe_gemini_code_request(prompt: str, max_retries: int = 3) -> str:
    """Gemini API ìš”ì²­ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ì½”ë“œ ìƒì„±ìš©)."""
    for attempt in range(max_retries):
        try:
            prompt_config = {
                "messages": [
                    {
                        "role": "user",
                        "parts": [prompt]
                    }
                ]
            }
            response = GeminiHandler.ask(prompt_config, model_name="gemini-2.5-pro")
            if response and response.strip():
                return response.strip()
        except Exception as e:
            print(f"  âš ï¸ Gemini code request attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
    return ""


def safe_gemini_label_request(prompt: str, max_retries: int = 3) -> str:
    """Gemini API ìš”ì²­ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ë ˆì´ë¸” ìƒì„±ìš©)."""
    for attempt in range(max_retries):
        try:
            prompt_config = {
                "messages": [
                    {
                        "role": "user",
                        "parts": [prompt]
                    }
                ]
            }
            response = GeminiHandler.ask(prompt_config, model_name="gemini-2.5-pro")
            if response and response.strip():
                return response.strip()
        except Exception as e:
            print(f"  âš ï¸ Gemini label request attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
    return ""


def process_single_task_for_generator(task: dict, generator_type: str) -> list[dict]:
    """í•˜ë‚˜ì˜ íƒœìŠ¤í¬ì— ëŒ€í•´ íŠ¹ì • ìƒì„±ê¸°ë¡œ Positive/Negative ìƒ˜í”Œ ìŒì„ ìƒì„±í•©ë‹ˆë‹¤."""
    final_entries = []
    task_type = task['type']
    patterns = task['patterns']

    print(f"  ğŸ”„ Processing task: {task['filename']} with {generator_type}")

    # ìƒì„±ê¸°ë³„ ê²½ë¡œ ì„¤ì •
    if generator_type == "claude":
        code_dir = GENERATED_CODE_CLAUDE
        label_dir = GENERATED_LABELS_CLAUDE
        prompt_dir = GENERATION_PROMPTS_CLAUDE
        code_request_func = safe_claude_request
    else:  # gemini
        code_dir = GENERATED_CODE_GEMINI
        label_dir = GENERATED_LABELS_GEMINI
        prompt_dir = GENERATION_PROMPTS_GEMINI
        code_request_func = safe_gemini_code_request

    samples_to_generate = [
        {"is_negative": False, "suffix": "positive"},
        {"is_negative": True, "suffix": "negative"}
    ]

    for sample_info in samples_to_generate:
        is_negative = sample_info['is_negative']
        suffix = sample_info['suffix']
        base_filename = f"{task['filename']}_{suffix}"

        code_path = code_dir / f"{base_filename}.swift"
        label_path = label_dir / f"{base_filename}.json"
        prompt_path = prompt_dir / f"{base_filename}.txt"

        # --- ì´ì–´í•˜ê¸° ë¡œì§ ---

        # 1. ì™„ë²½í•˜ê²Œ ì™„ë£Œëœ ê²½ìš°: .swiftì™€ .json íŒŒì¼ì´ ëª¨ë‘ ì¡´ì¬í•˜ê³  ìœ íš¨í•˜ë©´ ê±´ë„ˆëœ€
        if code_path.exists() and label_path.exists():
            try:
                swift_code = code_path.read_text(encoding='utf-8')
                json_output_str = label_path.read_text(encoding='utf-8')
                if swift_code.strip() and json_output_str.strip():
                    json.loads(json_output_str)  # JSON ìœ íš¨ì„± ê²€ì‚¬
                    symbol_info = run_swift_analyzer_on_code(swift_code)
                    if symbol_info:
                        print(f"  â¡ï¸ Using existing files for {base_filename}")
                        final_entries.append({
                            "instruction": "In the following Swift code, find all identifiers related to sensitive logic. Provide the names and reasoning as a JSON object.",
                            "input": create_alpaca_input(swift_code, symbol_info),
                            "output": json_output_str
                        })
                        continue  # ì´ ìƒ˜í”Œì€ ì™„ì „íˆ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ ë‹¤ìŒ ìƒ˜í”Œë¡œ ë„˜ì–´ê°
            except (json.JSONDecodeError, FileNotFoundError, Exception) as e:
                print(f"  âš ï¸ Error with existing files for {base_filename}, will regenerate. Error: {e}")

        # --- ì½”ë“œ ì¤€ë¹„ ë‹¨ê³„ ---
        generated_code = None

        # 2. ì½”ë“œë§Œ ì¡´ì¬í•˜ëŠ” ê²½ìš°: .swift íŒŒì¼ì„ ì½ì–´ì„œ ì‚¬ìš©í•˜ê³  ì½”ë“œ ìƒì„± ë‹¨ê³„ë¥¼ ê±´ë„ˆëœ€
        if code_path.exists():
            print(f"  â¡ï¸ Code file found for {base_filename}. Reusing it.")
            try:
                generated_code = code_path.read_text(encoding='utf-8').strip()
                if not generated_code:
                    print(f"  âš ï¸ Existing code file for {base_filename} is empty. Will regenerate.")
            except Exception as e:
                print(f"  âš ï¸ Could not read existing code file {code_path}: {e}. Will regenerate.")
                generated_code = None  # ì½ê¸° ì‹¤íŒ¨ ì‹œ ì¬ìƒì„±í•˜ë„ë¡ ì´ˆê¸°í™”

        # 3. ì½”ë“œê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°: APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì½”ë“œ ìƒì„±
        if not generated_code:
            print(f"  âœ¨ Generating new code for {base_filename}...")
            try:
                prompt = ""
                if task_type.startswith('Pure_nC1'):
                    prompt_template = GENERATE_SECURE_SINGLE_CODE_PROMPT if is_negative else GENERATE_SINGLE_CODE_PROMPT
                    prompt = prompt_template.format(pattern=patterns[0]['text'])
                elif task_type.startswith('Pure_nC2'):
                    prompt_template = GENERATE_SECURE_COMBINED_CODE_PROMPT if is_negative else GENERATE_COMBINED_CODE_PROMPT
                    prompt = prompt_template.format(pattern1=patterns[0]['text'], pattern2=patterns[1]['text'])
                elif task_type.startswith('Mixed'):
                    prompt_template = GENERATE_SECURE_MIXED_CONTEXT_CODE_PROMPT if is_negative else GENERATE_MIXED_CONTEXT_CODE_PROMPT
                    prompt = prompt_template.format(sensitive_pattern=patterns[0]['text'],
                                                    nonsensitive_pattern=patterns[1]['text'])

                api_response = code_request_func(prompt)
                if not api_response:
                    print(f"  âŒ Code generation API call failed for {base_filename}")
                    continue

                generated_code = api_response.removeprefix("```swift").removesuffix("```").strip()
                if not generated_code:
                    print(f"  âŒ Empty code after processing for {base_filename}")
                    continue

            except Exception as e:
                print(f"  âŒ Code generation error for {base_filename}: {e}")
                continue

        # --- AST ë¶„ì„ ë‹¨ê³„ ---
        try:
            symbol_info_json = run_swift_analyzer_on_code(generated_code)
            if not symbol_info_json:
                print(f"  âŒ AST analysis failed for {base_filename}")
                continue
        except Exception as e:
            print(f"  âŒ AST analysis error for {base_filename}: {e}")
            continue

        # --- ë ˆì´ë¸” ìƒì„± ë‹¨ê³„ (ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ ë™ì¼í•˜ê²Œ ì²˜ë¦¬) ---
        json_output_str = ""
        label_prompt_for_file = ""

        try:
            # ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš©
            label_prompt_for_file = f"""You are an expert security code auditor.
Your task is to identify all sensitive identifiers in the provided Swift code and explain your reasoning.
Analyze both the source code and its corresponding AST symbol information.

**Swift Source Code:**
```swift
{generated_code}
```

**AST Symbol Information (JSON):**
```json
{symbol_info_json}
```

Based on your analysis, provide your response as a JSON object with two keys: "reasoning" and "identifiers".

"reasoning": A brief step-by-step explanation of why the identified identifiers are considered sensitive. For secure code, explain why it is safe.

"identifiers": A JSON list of strings containing only the simple base name of each sensitive identifier. For secure code, this should be an empty list [].

Example for vulnerable code:
```json
{{
  "reasoning": "The `save` function is sensitive because it calls the `SecItemAdd` Keychain API. The `secretToken` variable holds the data being saved.",
  "identifiers": ["save", "secretToken"]
}}
```

Example for secure code:
```json
{{
  "reasoning": "This code correctly uses the Keychain to store secrets, which is a security best practice. Therefore, no sensitive identifiers were found.",
  "identifiers": []
}}
```

Your response must be ONLY the JSON object, following these rules exactly."""

            # API í˜¸ì¶œë¡œ ë ˆì´ë¸” ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            success = False
            for attempt in range(3):
                try:
                    raw_response = safe_gemini_label_request(label_prompt_for_file)
                    if not raw_response:
                        print(f"  âš ï¸ Empty response for {base_filename}, attempt {attempt + 1}")
                        continue

                    print(f"  ğŸ” Raw response length for {base_filename}: {len(raw_response)} chars")

                    # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ JSON ì¶”ì¶œ ì‹œë„
                    json_candidates = []

                    # ë°©ë²• 1: ê¸°ì¡´ extract_json_block
                    extracted_json = extract_json_block(raw_response)
                    if extracted_json:
                        json_candidates.append(extracted_json)

                    # ë°©ë²• 2: ê°„ë‹¨í•œ ì¤‘ê´„í˜¸ ì°¾ê¸°
                    start = raw_response.find('{')
                    end = raw_response.rfind('}')
                    if start != -1 and end != -1 and end > start:
                        simple_json = raw_response[start:end + 1]
                        if simple_json not in json_candidates:
                            json_candidates.append(simple_json)

                    # ê° í›„ë³´ì— ëŒ€í•´ ê²€ì¦
                    for candidate in json_candidates:
                        try:
                            output_data = json.loads(candidate)
                            if isinstance(output_data, dict) and "reasoning" in output_data and "identifiers" in output_data:
                                json_output_str = json.dumps(output_data, ensure_ascii=False, indent=2)
                                success = True
                                print(f"  âœ… JSON successfully parsed for {base_filename}")
                                break
                        except json.JSONDecodeError as e:
                            print(f"  âš ï¸ JSON candidate failed for {base_filename}: {e}")
                            continue

                    if success:
                        break
                    else:
                        print(f"  âŒ All JSON candidates failed for {base_filename}, attempt {attempt + 1}")
                        print(f"  ğŸ“„ Response preview: {raw_response[:200]}...")
                        time.sleep(2)

                except Exception as e:
                    print(f"  âš ï¸ Unexpected error for {base_filename}, attempt {attempt + 1}: {e}")
                    time.sleep(2)

            if not success:
                print(f"  âŒ Label generation failed for {base_filename} after 3 attempts. Skipping.")
                continue

        except Exception as e:
            print(f"  âŒ Label generation error for {base_filename}: {e}")
            continue

        # --- íŒŒì¼ ì €ì¥ ë° ìµœì¢… ì—”íŠ¸ë¦¬ ìƒì„± ---
        try:
            # ë””ë ‰í† ë¦¬ ìƒì„±
            code_path.parent.mkdir(parents=True, exist_ok=True)
            label_path.parent.mkdir(parents=True, exist_ok=True)
            prompt_path.parent.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ ì €ì¥
            prompt_path.write_text(label_prompt_for_file, encoding='utf-8')
            code_path.write_text(generated_code, encoding='utf-8')
            label_path.write_text(json_output_str, encoding='utf-8')

            # Alpaca í¬ë§· ì—”íŠ¸ë¦¬ ìƒì„±
            alpaca_input = create_alpaca_input(generated_code, symbol_info_json)

            final_entries.append({
                "instruction": "In the following Swift code, find all identifiers related to sensitive logic. Provide the names and reasoning as a JSON object.",
                "input": alpaca_input,
                "output": json_output_str
            })

        except Exception as e:
            print(f"  âŒ File saving error for {base_filename}: {e}")
            continue

    print(f"  âœ… Task {task['filename']} with {generator_type} completed: {len(final_entries)} entries")
    return final_entries


def generate_tasks(patterns_by_category: dict) -> list[dict]:
    """nC1, Intra-Category nC2, Cross-Category, Mixed ì¡°í•© íƒœìŠ¤í¬ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    print("ğŸ§  Generating comprehensive task list...")
    tasks = []

    sensitive_patterns = {k: v for k, v in patterns_by_category.items() if not k.startswith("NonSensitive_")}
    nonsensitive_patterns = [p for k, v in patterns_by_category.items() if k.startswith("NonSensitive_") for p in v]

    indexed_patterns = [
        {"id": f"{cat}_{i + 1}", "domain": cat.split('_')[0], "category": cat, "text": p}
        for cat, patterns in sensitive_patterns.items()
        for i, p in enumerate(patterns)
    ]

    # --- ìˆœìˆ˜(Pure) íƒœìŠ¤í¬ ìƒì„± ---
    # nC1
    for p in indexed_patterns:
        tasks.append({"type": "Pure_nC1", "patterns": [p], "filename": p['id']})
    # Intra-Category nC2
    for cat in sensitive_patterns.keys():
        patterns_in_cat = [p for p in indexed_patterns if p['category'] == cat]
        if len(patterns_in_cat) >= 2:
            for p1, p2 in itertools.combinations(patterns_in_cat, 2):
                tasks.append({"type": "Pure_nC2", "patterns": [p1, p2], "filename": f"{p1['id']}_{p2['id']}"})

    # --- í˜¼í•©í˜•(Mixed) íƒœìŠ¤í¬ ìƒì„± ---
    if nonsensitive_patterns:
        for sens_p in indexed_patterns:
            nonsens_p_text = random.choice(nonsensitive_patterns)
            tasks.append({
                "type": "Mixed",
                "patterns": [sens_p, {"text": nonsens_p_text}],
                "filename": f"Mixed_{sens_p['id']}"
            })

    unique_tasks = {task['filename']: task for task in tasks}.values()
    print(f"âœ… Task list generated. Total unique tasks: {len(unique_tasks)} (each will create a positive/negative pair)")
    return list(unique_tasks)


# --- 3. ë©”ì¸ íŒŒì´í”„ë¼ì¸ (Main Pipeline) ---
def main_pipeline():
    """ìµœì¢… ë°ì´í„°ì…‹ ìƒì„± íŒŒì´í”„ë¼ì¸ (Claude + Gemini ì½”ë“œ ìƒì„±, Gemini ë ˆì´ë¸” ìƒì„±)"""
    print("ğŸš€ Starting Alpaca dataset generation pipeline...")
    print("  ğŸ“ Claude: Code generation")
    print("  ğŸ“ Gemini: Code generation")
    print("  ğŸ·ï¸  Gemini: Label generation (for both)")

    # ëª¨ë“  ë””ë ‰í† ë¦¬ ìƒì„±
    for dir_path in [GENERATED_CODE_CLAUDE, GENERATED_CODE_GEMINI,
                     GENERATED_LABELS_CLAUDE, GENERATED_LABELS_GEMINI,
                     GENERATION_PROMPTS_CLAUDE, GENERATION_PROMPTS_GEMINI]:
        dir_path.mkdir(parents=True, exist_ok=True)

    # íŒ¨í„´ ë¡œë“œ
    try:
        with open(PATTERNS_FILE, "r", encoding="utf-8") as f:
            patterns_by_category = json.load(f)
    except Exception as e:
        print(f"âŒ Failed to load patterns file: {e}")
        return

    tasks = generate_tasks(patterns_by_category)

    claude_dataset = []
    gemini_dataset = []
    combined_dataset = []

    # Claude ìƒì„±ê¸°ë¡œ ì²˜ë¦¬
    print("\nğŸ”µ Processing with Claude code generator...")
    for i, task in enumerate(tqdm(tasks, desc="Processing tasks with Claude")):
        try:
            entries = process_single_task_for_generator(task, "claude")
            if entries:
                claude_dataset.extend(entries)
                combined_dataset.extend(entries)
        except Exception as exc:
            print(f"  âŒ Claude task {task['filename']} generated an exception: {exc}")
            import traceback
            traceback.print_exc()

    # Gemini ìƒì„±ê¸°ë¡œ ì²˜ë¦¬
    print("\nğŸŸ¡ Processing with Gemini code generator...")
    for i, task in enumerate(tqdm(tasks, desc="Processing tasks with Gemini")):
        try:
            entries = process_single_task_for_generator(task, "gemini")
            if entries:
                gemini_dataset.extend(entries)
                combined_dataset.extend(entries)
        except Exception as exc:
            print(f"  âŒ Gemini task {task['filename']} generated an exception: {exc}")
            import traceback
            traceback.print_exc()

    # ìµœì¢… ë°ì´í„°ì…‹ íŒŒì¼ë“¤ ì €ì¥
    try:
        # Claude only dataset
        with open(FINAL_DATASET_CLAUDE_ONLY, "w", encoding="utf-8") as f:
            for entry in claude_dataset:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")

        # Gemini only dataset
        with open(FINAL_DATASET_GEMINI_ONLY, "w", encoding="utf-8") as f:
            for entry in gemini_dataset:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")

        # Combined dataset
        with open(FINAL_DATASET_COMBINED, "w", encoding="utf-8") as f:
            for entry in combined_dataset:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")

        print(f"\nâœ… Pipeline finished!")
        print(f"ğŸ“Š Claude dataset: {len(claude_dataset)} entries -> {FINAL_DATASET_CLAUDE_ONLY}")
        print(f"ğŸ“Š Gemini dataset: {len(gemini_dataset)} entries -> {FINAL_DATASET_GEMINI_ONLY}")
        print(f"ğŸ“Š Combined dataset: {len(combined_dataset)} entries -> {FINAL_DATASET_COMBINED}")

    except Exception as e:
        print(f"âŒ Failed to save final datasets: {e}")


if __name__ == "__main__":
    main_pipeline()