import time
import re
import json
import subprocess
import tempfile
from pathlib import Path
from tqdm import tqdm
import itertools
import random
import concurrent.futures
from prompts import (
    GENERATE_SINGLE_CODE_PROMPT, GENERATE_COMBINED_CODE_PROMPT,
    GENERATE_SECURE_SINGLE_CODE_PROMPT, GENERATE_SECURE_COMBINED_CODE_PROMPT,
    GENERATE_MIXED_CONTEXT_CODE_PROMPT, GENERATE_SECURE_MIXED_CONTEXT_CODE_PROMPT
)
from claude_handler.claude_handler import ClaudeHandler  # ì½”ë“œ ìƒì„±ìš©
from gemini_handler.gemini_handler import GeminiHandler  # ì½”ë“œ ìƒì„± + ë ˆì´ë¸” ìƒì„±ìš©

# --- í…ŒìŠ¤íŠ¸ ì „ìš© ì„¤ì • ---
ANALYZER_EXECUTABLE = "./SwiftASTAnalyzer/.build/release/SwiftASTAnalyzer"
PATTERNS_FILE = "./patterns.json"
OUTPUT_DIR = Path("./output")

# í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ë³¸ ê²½ë¡œ (ê¸°ì¡´ êµ¬ì¡°ì™€ ë™ì¼)
TEST_BASE_DIR = OUTPUT_DIR / "generated_code" / "test"
TEST_INPUTS_BASE_DIR = OUTPUT_DIR / "inputs" / "test"
TEST_OUTPUTS_BASE_DIR = OUTPUT_DIR / "outputs" / "test"


# --- í—¬í¼ í•¨ìˆ˜ë“¤ ---

def get_test_projects() -> list:
    """test ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  í”„ë¡œì íŠ¸ í´ë”ë¥¼ ì§€ì •ëœ ìˆœì„œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # ì²˜ë¦¬ ìˆœì„œ ê°•ì œ: UIKit+SPM_2 -> ConfettiSwiftUI -> iOS -> UIKit+SPM_1
    priority_order = [
        "Code_UIKit+SPM_2_combined",
        "Code_ConfettiSwiftUI",
        "Code_iOS",
        "Code_UIKit+SPM_1_combined"
    ]

    test_projects = []
    if TEST_BASE_DIR.exists():
        existing_projects = set()
        for item in TEST_BASE_DIR.iterdir():
            if item.is_dir():
                existing_projects.add(item.name)

        # ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ ì¶”ê°€
        for project in priority_order:
            if project in existing_projects:
                test_projects.append(project)
                existing_projects.remove(project)

        # ë‚˜ë¨¸ì§€ í”„ë¡œì íŠ¸ë“¤ì€ ì•ŒíŒŒë²³ ìˆœìœ¼ë¡œ ì¶”ê°€
        for project in sorted(existing_projects):
            test_projects.append(project)

    return test_projects


def get_test_project_paths(project_name: str) -> dict:
    """í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return {
        "code": TEST_BASE_DIR / project_name,
        "inputs": TEST_INPUTS_BASE_DIR / project_name,
        "labels": TEST_OUTPUTS_BASE_DIR / project_name
    }


def discover_existing_test_files():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ì—ì„œ ê¸°ì¡´ Swift íŒŒì¼ë“¤ì„ ë°œê²¬í•©ë‹ˆë‹¤."""
    test_tasks = []
    test_projects = get_test_projects()

    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ë“¤ì—ì„œ ê¸°ì¡´ Swift íŒŒì¼ ê²€ìƒ‰ ì¤‘...")

    for project in test_projects:
        project_code_dir = TEST_BASE_DIR / project
        if not project_code_dir.exists():
            print(f"  - {project}: ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            continue

        swift_files = list(project_code_dir.glob("*.swift"))
        print(f"  - {project}: {len(swift_files)}ê°œì˜ Swift íŒŒì¼ ë°œê²¬")

        for swift_file in swift_files:
            task_name = swift_file.stem
            test_tasks.append({
                "project": project,
                "filename": task_name,
                "file_path": swift_file,
                "type": "Existing_Code"
            })

    return test_tasks


def extract_json_block(text: str) -> str | None:
    """í…ìŠ¤íŠ¸ì—ì„œ JSON ë¸”ë¡ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not text or not isinstance(text, str):
        return None

    text = text.strip()

    # 1. ```json ... ``` ë¸”ë¡ ê²€ìƒ‰
    json_block_patterns = [
        r"```json\s*(\{.*?\})\s*```",
        r"```\s*(\{.*?\})\s*```",
        r"```json\s*([\s\S]*?)\s*```",
        r"```\s*([\s\S]*?)\s*```"
    ]

    for pattern in json_block_patterns:
        try:
            match = re.search(pattern, text, re.DOTALL | re.MULTILINE)
            if match:
                json_candidate = match.group(1).strip()
                if json_candidate and validate_and_return_json(json_candidate):
                    return json_candidate
        except Exception:
            continue

    # 2. ë¸”ë¡ ë§ˆì»¤ ì—†ì´ JSON ê°ì²´ ì°¾ê¸°
    return extract_json_from_text(text)


def extract_json_from_text(text: str) -> str | None:
    """í…ìŠ¤íŠ¸ì—ì„œ ìœ íš¨í•œ JSON ê°ì²´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        # ì¤„ë³„ë¡œ ì²˜ë¦¬í•˜ì—¬ JSON ì‹œì‘ì  ì°¾ê¸°
        lines = text.split('\n')
        json_start_line = -1

        # JSONì´ ì‹œì‘ë  ê²ƒ ê°™ì€ ë¼ì¸ ì°¾ê¸°
        for i, line in enumerate(lines):
            stripped_line = line.strip()
            if stripped_line.startswith('{'):
                json_start_line = i
                break

        if json_start_line == -1:
            return None

        # JSON ëì  ì°¾ê¸° (ì¤‘ê´„í˜¸ ê· í˜•)
        brace_count = 0
        json_lines = []

        for i in range(json_start_line, len(lines)):
            line = lines[i]
            json_lines.append(line)

            for char in line:
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1

            if brace_count == 0 and len(json_lines) > 0:
                # JSON ê°ì²´ê°€ ì™„ì„±ë¨
                json_text = '\n'.join(json_lines)
                return validate_and_return_json(json_text.strip())

        # ì¤‘ê´„í˜¸ê°€ ê· í˜•ì„ ì´ë£¨ì§€ ëª»í•œ ê²½ìš°, ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ JSON ì‹œë„
        return validate_and_return_json(text)

    except Exception:
        return None


def validate_and_return_json(json_text: str) -> str | None:
    """JSON í…ìŠ¤íŠ¸ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not json_text:
        return None

    try:
        # ì•ë’¤ ê³µë°± ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
        json_text = json_text.strip()

        # JSON íŒŒì‹± ì‹œë„
        parsed = json.loads(json_text)

        # ê¸°ëŒ€í•˜ëŠ” êµ¬ì¡° í™•ì¸ (reasoning, identifiers í•„ë“œ)
        if isinstance(parsed, dict) and "reasoning" in parsed and "identifiers" in parsed:
            # ìœ íš¨í•œ JSONì´ë¯€ë¡œ ì›ë³¸ ë°˜í™˜ (í¬ë§·íŒ… ë³´ì¡´)
            return json_text

    except (json.JSONDecodeError, TypeError, AttributeError) as e:
        # JSON íŒŒì‹± ì‹¤íŒ¨ - ì¼ë°˜ì ì¸ ë¬¸ì œë“¤ì„ ìˆ˜ì • ì‹œë„
        try:
            # í”í•œ ë¬¸ì œë“¤ ìˆ˜ì •
            fixed_json = fix_common_json_issues(json_text)
            if fixed_json and fixed_json != json_text:
                parsed = json.loads(fixed_json)
                if isinstance(parsed, dict) and "reasoning" in parsed and "identifiers" in parsed:
                    return fixed_json
        except Exception:
            pass

    return None


def fix_common_json_issues(json_text: str) -> str:
    """ì¼ë°˜ì ì¸ JSON í˜•ì‹ ë¬¸ì œë“¤ì„ ìˆ˜ì •í•©ë‹ˆë‹¤."""
    if not json_text:
        return json_text

    try:
        # 1. ì•ë’¤ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
        json_text = json_text.strip()

        # 2. ì‹œì‘ê³¼ ëì´ ì¤‘ê´„í˜¸ê°€ ì•„ë‹Œ ê²½ìš° ì°¾ê¸°
        start_idx = json_text.find('{')
        end_idx = json_text.rfind('}')

        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            json_text = json_text[start_idx:end_idx + 1]

        # 3. ë”°ì˜´í‘œ ë¬¸ì œ ìˆ˜ì • (ë‹¨ìˆœí•œ ê²½ìš°ë§Œ)
        json_text = re.sub(r'([{,]\s*)(\w+)(\s*:)', r'\1"\2"\3', json_text)

        # 4. í›„í–‰ ì‰¼í‘œ ì œê±°
        json_text = re.sub(r',(\s*[}\]])', r'\1', json_text)

        return json_text

    except Exception:
        return json_text


def run_swift_analyzer_on_code(swift_code: str) -> str | None:
    """Swift ì½”ë“œë¥¼ ì„ì‹œ íŒŒì¼ì— ì €ì¥í•˜ê³  ë¶„ì„ê¸°ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‹¬ë³¼ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not swift_code or not swift_code.strip():
        return None

    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_file_path = Path(temp_dir) / "temp.swift"
            temp_file_path.write_text(swift_code, encoding='utf-8')
            command = [ANALYZER_EXECUTABLE, str(temp_file_path.absolute())]

            process = subprocess.run(
                command,
                capture_output=True,
                text=True,
                check=True,
                encoding='utf-8',
                timeout=30
            )
            return process.stdout.strip() if process.stdout else None

    except (subprocess.CalledProcessError, subprocess.TimeoutExpired, Exception) as e:
        print(f"  âš ï¸ Swift analyzer failed: {e}")
        return None


def create_alpaca_input(swift_code: str, symbol_info_json: str) -> str:
    """ëª¨ë¸ì´ í•™ìŠµí•  Input í•„ë“œë¥¼ í˜•ì‹ì— ë§ê²Œ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        symbol_info_pretty = json.dumps(json.loads(symbol_info_json), indent=2, ensure_ascii=False)
    except (json.JSONDecodeError, TypeError):
        symbol_info_pretty = symbol_info_json

    return f"""**Swift Source Code:**
```swift
{swift_code}
```

**AST Symbol Information (JSON):**
```
{symbol_info_pretty}
```"""


def safe_gemini_label_request(prompt: str, max_retries: int = 3) -> str:
    """Gemini API ìš”ì²­ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ë ˆì´ë¸” ìƒì„±ìš©)."""
    for attempt in range(max_retries):
        try:
            prompt_config = {
                "messages": [
                    {
                        "role": "user",
                        "parts": [prompt]
                    }
                ]
            }
            response = GeminiHandler.ask(prompt_config, model_name="gemini-2.5-pro")
            if response and response.strip():
                return response.strip()
        except Exception as e:
            print(f"  âš ï¸ Gemini label request attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
    return ""


def process_existing_test_file(test_task: dict):
    """ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ë¼ë²¨ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    project = test_task["project"]
    filename = test_task["filename"]
    file_path = test_task["file_path"]

    paths = get_test_project_paths(project)
    code_path = paths["code"] / f"{filename}.swift"
    input_path = paths["inputs"] / f"{filename}.txt"
    label_path = paths["labels"] / f"{filename}.json"

    # ì´ë¯¸ ìœ íš¨í•œ ë¼ë²¨ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
    try:
        if label_path.exists() and label_path.stat().st_size > 10:
            content = label_path.read_text(encoding='utf-8').strip()
            if content:
                json.loads(content)  # JSON ìœ íš¨ì„± ê²€ì‚¬
                print(f"  - [TEST/{project}] `{filename}` - ì´ë¯¸ ì²˜ë¦¬ë¨, ìŠ¤í‚µ")
                return
    except (json.JSONDecodeError, UnicodeDecodeError, OSError):
        pass

    print(f"  - [TEST/{project}] `{filename}` ì²˜ë¦¬ ì¤‘...")

    # Swift ì½”ë“œ ì½ê¸°
    try:
        swift_code = code_path.read_text(encoding='utf-8')
        if not swift_code or not swift_code.strip():
            print(f"    âŒ Swift ì½”ë“œê°€ ë¹„ì–´ìˆìŒ")
            return
    except Exception as e:
        print(f"    âŒ Swift ì½”ë“œ ì½ê¸° ì‹¤íŒ¨: {e}")
        return

    # AST ë¶„ì„
    symbol_info_json = run_swift_analyzer_on_code(swift_code)
    if not symbol_info_json:
        print(f"    âŒ Swift analyzer ì‹¤íŒ¨ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•Šì€ JSON ë°˜í™˜")
        return

    # ë¼ë²¨ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì €ì¥
    try:
        label_prompt = f"""You are an expert security code auditor.
Your task is to identify all sensitive identifiers in the provided Swift code and explain your reasoning.
Analyze both the source code and its corresponding AST symbol information.

**Swift Source Code:**
```swift
{swift_code}
```

**AST Symbol Information (JSON):**
```json
{symbol_info_json}
```

Based on your analysis, provide your response as a JSON object with two keys: "reasoning" and "identifiers".

"reasoning": A brief step-by-step explanation of why the identified identifiers are considered sensitive. For secure code, explain why it is safe.

"identifiers": A JSON list of strings containing only the simple base name of each sensitive identifier. For secure code, this should be an empty list [].

Example for vulnerable code:
```json
{{
  "reasoning": "The `save` function is sensitive because it calls the `SecItemAdd` Keychain API. The `secretToken` variable holds the data being saved.",
  "identifiers": ["save", "secretToken"]
}}
```

Example for secure code:
```json
{{
  "reasoning": "This code correctly uses the Keychain to store secrets, which is a security best practice. Therefore, no sensitive identifiers were found.",
  "identifiers": []
}}
```

Your response must be ONLY the JSON object, following these rules exactly."""

        input_path.write_text(label_prompt, encoding='utf-8')
    except Exception as e:
        print(f"    âŒ ì…ë ¥ í”„ë¡¬í”„íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        return

    # ë¼ë²¨ ìƒì„± (Gemini ì‚¬ìš©)
    success = False
    final_output_json_str = ""

    for attempt in range(3):
        try:
            raw_response = safe_gemini_label_request(label_prompt)
            if not raw_response:
                print(f"    âš ï¸ Empty response for {project}/{filename}, attempt {attempt + 1}")
                continue

            print(f"    ğŸ” Raw response length for {project}/{filename}: {len(raw_response)} chars")

            # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ JSON ì¶”ì¶œ ì‹œë„
            json_candidates = []

            # ë°©ë²• 1: ê¸°ì¡´ extract_json_block
            extracted_json = extract_json_block(raw_response)
            if extracted_json:
                json_candidates.append(extracted_json)

            # ë°©ë²• 2: ê°„ë‹¨í•œ ì¤‘ê´„í˜¸ ì°¾ê¸°
            start = raw_response.find('{')
            end = raw_response.rfind('}')
            if start != -1 and end != -1 and end > start:
                simple_json = raw_response[start:end + 1]
                if simple_json not in json_candidates:
                    json_candidates.append(simple_json)

            # ê° í›„ë³´ì— ëŒ€í•´ ê²€ì¦
            for candidate in json_candidates:
                try:
                    output_data = json.loads(candidate)
                    if isinstance(output_data, dict) and "reasoning" in output_data and "identifiers" in output_data:
                        final_output_json_str = json.dumps(output_data, ensure_ascii=False, indent=2)
                        success = True
                        print(f"    âœ… JSON successfully parsed for {project}/{filename}")
                        break
                except json.JSONDecodeError as e:
                    print(f"    âš ï¸ JSON candidate failed for {project}/{filename}: {e}")
                    continue

            if success:
                break
            else:
                print(f"    âŒ All JSON candidates failed for {project}/{filename}, attempt {attempt + 1}")
                print(f"    ğŸ“„ Response preview: {raw_response[:200]}...")
                time.sleep(2)

        except Exception as e:
            print(f"    âš ï¸ Unexpected error for {project}/{filename}, attempt {attempt + 1}: {e}")
            time.sleep(2)

    if not success:
        print(f"    âŒ Label generation failed for {project}/{filename} after 3 attempts.")
        try:
            label_path.write_text('{"error": "generation_failed"}', encoding='utf-8')
        except Exception:
            pass
        return

    # ìµœì¢… ì €ì¥
    try:
        label_path.write_text(final_output_json_str, encoding='utf-8')
        print(f"    âœ… `{filename}` ì²˜ë¦¬ ì™„ë£Œ")
    except Exception as e:
        print(f"    âŒ ë¼ë²¨ ì €ì¥ ì‹¤íŒ¨: {e}")
        return


def assemble_test_datasets():
    """í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ë³„ë¡œ ìµœì¢… ë°ì´í„°ì…‹ì„ ì¡°ë¦½í•©ë‹ˆë‹¤."""
    print("\nğŸ“¦ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¡°ë¦½ ì¤‘...")

    test_projects = get_test_projects()
    all_test_data = []
    project_counts = {}

    for project in test_projects:
        print(f"\n  - {project} í”„ë¡œì íŠ¸ ì²˜ë¦¬ ì¤‘...")

        paths = get_test_project_paths(project)
        label_files = sorted(list(paths["labels"].glob("*.json")))

        if not label_files:
            print(f"    ë¼ë²¨ íŒŒì¼ ì—†ìŒ")
            project_counts[project] = 0
            continue

        project_data = []
        success_count = 0
        error_count = 0

        for label_path in tqdm(label_files, desc=f"{project} ë°ì´í„°ì…‹ ì¡°ë¦½"):
            try:
                # ìœ íš¨í•œ JSON íŒŒì¼ì¸ì§€ í™•ì¸
                try:
                    if not label_path.exists() or label_path.stat().st_size <= 10:
                        error_count += 1
                        continue
                    content = label_path.read_text(encoding='utf-8').strip()
                    if not content or content == "":
                        error_count += 1
                        continue
                    json.loads(content)  # JSON ìœ íš¨ì„± ê²€ì‚¬
                except (json.JSONDecodeError, UnicodeDecodeError, OSError):
                    error_count += 1
                    continue

                code_path = paths["code"] / (label_path.stem + ".swift")
                input_path = paths["inputs"] / (label_path.stem + ".txt")

                if not code_path.exists() or not input_path.exists():
                    error_count += 1
                    continue

                swift_code = code_path.read_text(encoding='utf-8')
                if not swift_code or not swift_code.strip():
                    error_count += 1
                    continue

                output_json_str = label_path.read_text(encoding='utf-8')
                input_prompt = input_path.read_text(encoding='utf-8')

                # input í”„ë¡¬í”„íŠ¸ì—ì„œ symbol_infoë¥¼ ì¶”ì¶œ
                symbol_info_json = None
                if "AST Symbol Information (JSON):" in input_prompt:
                    match = re.search(r'AST Symbol Information \(JSON\):\s*```\s*(.*?)\s*```', input_prompt, re.DOTALL)
                    if match:
                        symbol_info_json = match.group(1).strip()

                # ë§Œì•½ ì¶”ì¶œì— ì‹¤íŒ¨í•˜ë©´ Swift analyzer ë‹¤ì‹œ ì‹¤í–‰
                if not symbol_info_json:
                    symbol_info_json = run_swift_analyzer_on_code(swift_code)
                    if not symbol_info_json:
                        error_count += 1
                        continue

                # JSON íŒŒì‹± ê²€ì¦
                try:
                    symbol_info_dict = json.loads(symbol_info_json)
                    output_dict = json.loads(output_json_str)
                except json.JSONDecodeError:
                    error_count += 1
                    continue

                # ìµœì¢… ë°ì´í„°ì…‹ ì—”íŠ¸ë¦¬ ìƒì„±
                entry = {
                    "instruction": "In the following Swift code, find all identifiers related to sensitive logic. Provide the names and reasoning as a JSON object.",
                    "input": create_alpaca_input(swift_code, symbol_info_json),
                    "output": output_json_str
                }

                project_data.append(entry)
                all_test_data.append(entry)
                success_count += 1

            except Exception as e:
                error_count += 1
                print(f"\nâš ï¸ íŒŒì¼ ì¡°ë¦½ ì¤‘ ì—ëŸ¬ ë°œìƒ '{label_path.name}': {e}")

        project_counts[project] = success_count
        print(f"    {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")

        # í”„ë¡œì íŠ¸ë³„ ë°ì´í„°ì…‹ íŒŒì¼ ì €ì¥
        if project_data:
            try:
                project_dataset_file = OUTPUT_DIR / f"test_{project}_dataset.jsonl"
                with open(project_dataset_file, "w", encoding="utf-8") as f:
                    for entry in project_data:
                        f.write(json.dumps(entry, ensure_ascii=False) + "\n")
                print(f"    ì €ì¥ë¨: {project_dataset_file}")
            except Exception as e:
                print(f"    âŒ í”„ë¡œì íŠ¸ ë°ì´í„°ì…‹ ì €ì¥ ì‹¤íŒ¨: {e}")

    # ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì €ì¥
    if all_test_data:
        try:
            all_test_dataset_file = OUTPUT_DIR / "all_test_dataset.jsonl"
            with open(all_test_dataset_file, "w", encoding="utf-8") as f:
                for entry in all_test_data:
                    f.write(json.dumps(entry, ensure_ascii=False) + "\n")
            print(f"\nì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì €ì¥ë¨: {all_test_dataset_file}")
        except Exception as e:
            print(f"\nâŒ ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì €ì¥ ì‹¤íŒ¨: {e}")

    return project_counts, len(all_test_data)


def main_test_existing_pipeline():
    """ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ëŠ” íŒŒì´í”„ë¼ì¸"""
    print("ğŸ§ª ê¸°ì¡´ í…ŒìŠ¤íŠ¸ Swift íŒŒì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")

    # í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
    test_projects = get_test_projects()
    if not test_projects:
        print("âŒ í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print(f"   {TEST_BASE_DIR} ë””ë ‰í† ë¦¬ì— í”„ë¡œì íŠ¸ í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    print(f"ë°œê²¬ëœ í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸: {test_projects}")

    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
    for project in test_projects:
        paths = get_test_project_paths(project)
        for path in paths.values():
            path.mkdir(parents=True, exist_ok=True)

    # 1. ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤ ë°œê²¬
    test_tasks = discover_existing_test_files()
    if not test_tasks:
        print("âŒ ì²˜ë¦¬í•  Swift íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return

    print(f"\nì´ {len(test_tasks)}ê°œì˜ ê¸°ì¡´ Swift íŒŒì¼ ë°œê²¬")

    # 2. ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìƒ˜í”Œ ìƒì„±
    print("\nğŸ”„ ê¸°ì¡´ Swift íŒŒì¼ë“¤ ì²˜ë¦¬ ì‹œì‘...")
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        list(tqdm(
            executor.map(process_existing_test_file, test_tasks),
            total=len(test_tasks),
            desc="ê¸°ì¡´ Swift íŒŒì¼ ì²˜ë¦¬ ì¤‘"
        ))

    # 3. ìµœì¢… ë°ì´í„°ì…‹ ì¡°ë¦½
    project_counts, total_count = assemble_test_datasets()

    # 4. ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ… ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    for project, count in project_counts.items():
        print(f"   - {project}: {count}ê°œ ë°ì´í„°")
    print(f"   - ì´ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {total_count}ê°œ ìƒì„± ì™„ë£Œ")

    # ì €ì¥ëœ íŒŒì¼ë“¤ ì •ë¦¬
    print(f"\nğŸ“„ ìƒì„±ëœ ë°ì´í„°ì…‹ íŒŒì¼ë“¤:")
    for project in test_projects:
        if project_counts.get(project, 0) > 0:
            print(f"   - test_{project}_dataset.jsonl")
    if total_count > 0:
        print(f"   - all_test_dataset.jsonl")


if __name__ == "__main__":
    main_test_existing_pipeline()